{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organized-beverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyostie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "necessary-genetics",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pyostie.extract('/home/anirudhpnbb/Downloads/Patterson Invoice 1.pdf', insights=True, extension=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eleven-starter",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, text = output.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postal-fifty",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-adolescent",
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "willing-chrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "\n",
    "class generate_insights:\n",
    "\n",
    "    def __init__(self, filename, data):\n",
    "        \"\"\"\n",
    "\n",
    "        :param filename: Input the filename as string.\n",
    "        :param data: Input an empty dataframe.\n",
    "        \"\"\"\n",
    "        self.file = filename\n",
    "        self.data = data\n",
    "\n",
    "    def generate_df(self):\n",
    "        \"\"\"\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        top_plus_height = []\n",
    "        left_plus_width = []\n",
    "        img = cv2.imread(self.file)\n",
    "        image = Image.open(self.file)\n",
    "        w, h = image.size\n",
    "        d = pytesseract.image_to_data(img, output_type=Output.DICT)\n",
    "        self.data = self.data.assign(**d)\n",
    "        self.data.replace(\"\", np.NaN, inplace=True)\n",
    "        self.data.replace(\" \", np.NaN, inplace=True)\n",
    "        self.data.dropna(subset=[\"text\"], inplace=True)\n",
    "        self.data = self.data.reset_index()\n",
    "        self.data = self.data.drop([\"index\", \"block_num\", \"level\"], 1)\n",
    "        image_width = [w] * len(self.data)\n",
    "        image_height = [h] * len(self.data)\n",
    "        self.data[\"conf\"] = [i / 100 for i in self.data[\"conf\"]]\n",
    "        self.data[\"image_width\"] = image_width\n",
    "        self.data[\"image_height\"] = image_height\n",
    "        for val in range(len(self.data)):\n",
    "            output = self.data[\"left\"][val] + self.data[\"width\"][val]\n",
    "            left_plus_width.append(output)\n",
    "        for val in range(len(self.data)):\n",
    "            output = self.data[\"top\"][val] + self.data[\"height\"][val]\n",
    "            top_plus_height.append(output)\n",
    "        self.data[\"top_plus_height\"] = top_plus_height\n",
    "        self.data[\"left_plus_width\"] = left_plus_width\n",
    "        self.data['topLeft'] = tuple(self.data[['left', 'top']].\n",
    "                                     apply(lambda x: ','.join(x.fillna('').map(str)), axis=1))\n",
    "        self.data['bottomLeft'] = tuple(self.data[['left', 'top_plus_height']].\n",
    "                                        apply(lambda x: ','.join(x.fillna('').map(str)), axis=1))\n",
    "        self.data['bottomRight'] = tuple(self.data[['left_plus_width', 'top_plus_height']].\n",
    "                                         apply(lambda x: ','.join(x.fillna('').map(str)), axis=1))\n",
    "        self.data['topRight'] = tuple(self.data[['left_plus_width', 'top']].\n",
    "                                      apply(lambda x: ','.join(x.fillna('').map(str)), axis=1))\n",
    "        self.data['topLeft'] = self.data['topLeft'].str.strip(',')\n",
    "        self.data['bottomLeft'] = self.data['bottomLeft'].str.strip(',')\n",
    "        self.data['bottomRight'] = self.data['bottomRight'].str.strip(',')\n",
    "        self.data['topRight'] = self.data['topRight'].str.strip(',')\n",
    "        self.data = self.data.drop([\"left_plus_width\", \"top_plus_height\"], 1)\n",
    "\n",
    "        return self.data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "worthy-comedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import datetime\n",
    "\n",
    "extensions = {\"jpeg\": \"jpg\", \"tiff\":\"jpg\", \"tif\": \"jpg\", \"\":\"txt\", \"log\":\"txt\", \"xls\": \"xlsx\"}\n",
    "\n",
    "\n",
    "def process_files(file_list, output_path, folder_name):\n",
    "    try:\n",
    "        if os.path.isdir(folder_name):\n",
    "            x = datetime.datetime.today().strftime('%d%m%Y_%H%M') + '_azure_json_processed_files'\n",
    "            os.mkdir(output_path + x)\n",
    "            for i in file_list:\n",
    "                shutil.move(i, output_path + x)\n",
    "            shutil.make_archive(output_path + x, 'zip', output_path, x)\n",
    "            shutil.rmtree(output_path + x)\n",
    "        elif not os.path.isdir(folder_name):\n",
    "            os.mkdir(folder_name)\n",
    "            x = datetime.datetime.today().strftime('%d%m%Y_%H%M') + '_azure_json_processed_files'\n",
    "            os.mkdir(output_path + x)\n",
    "            for i in file_list:\n",
    "                shutil.move(i, output_path + x)\n",
    "            shutil.make_archive(output_path + x, 'zip', output_path, x)\n",
    "            shutil.rmtree(output_path + x)\n",
    "        else:\n",
    "            print(\"Please check and try again.\")\n",
    "    except Exception as ex:\n",
    "        raise ex\n",
    "\n",
    "\n",
    "def remove_files(filename_with_path):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    if os.path.isfile(filename_with_path):\n",
    "        os.remove(filename_with_path)\n",
    "\n",
    "\n",
    "def extension_type_check(extension, input_type):\n",
    "    def decorator(function):\n",
    "        def wrapper(args):\n",
    "            if isinstance(args, input_type):\n",
    "                extnsn = extensions.get(extension, extension)\n",
    "                return extnsn\n",
    "            else:\n",
    "                print(\"Bad input type.\")\n",
    "        return wrapper\n",
    "    return decorator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "robust-muscle",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "\n",
    "\n",
    "class conversion:\n",
    "\n",
    "    def __init__(self, filename):\n",
    "        \"\"\"\n",
    "\n",
    "        :param output_list:\n",
    "        \"\"\"\n",
    "        self.file = filename\n",
    "\n",
    "    def convert(self):\n",
    "        \"\"\"\n",
    "\n",
    "        :return:\n",
    "        \"\"\"\n",
    "#         if self.file[-3::].upper() == \"PDF\":\n",
    "        pages = convert_from_path(self.file, 500)\n",
    "        pages[0].save(self.file[:-4] + '.jpg', \"JPEG\")\n",
    "        return self.file[:-4] + \".jpg\"\n",
    "\n",
    "    def remove_file(self, file_to_remove):\n",
    "        os.remove(file_to_remove)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "illegal-tomorrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "class pdf:\n",
    "\n",
    "    def __init__(self, filename, insights=False):\n",
    "        \"\"\"\n",
    "\n",
    "        :param filename:\n",
    "        :param insights:\n",
    "        \"\"\"\n",
    "        self.file = filename\n",
    "        self.insights = insights\n",
    "\n",
    "    def extract_pypdf2(self):\n",
    "        \"\"\"\n",
    "\n",
    "        :param kwargs:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        contents = []\n",
    "        text = ' '\n",
    "        pdfFileObj = open(self.file, 'rb')\n",
    "        pdfReader = PyPDF2.PdfFileReader(pdfFileObj)\n",
    "        pdfPages = pdfReader.getNumPages()\n",
    "        if pdfPages == 1:\n",
    "            for val in range(pdfReader.numPages):\n",
    "                pageObject = pdfReader.getPage(val)\n",
    "                text = text + pageObject.extractText()\n",
    "            contents.append(text)\n",
    "            if self.insights:\n",
    "                conv = conversion(self.file)\n",
    "                __conv = conv.convert()\n",
    "                insights = generate_insights(__conv, df)\n",
    "                __insights = insights.generate_df()\n",
    "                remove_files(__conv)\n",
    "                return __insights, contents\n",
    "            else:\n",
    "                return contents\n",
    "\n",
    "        if pdfPages >= 2:\n",
    "            print(\"We are currently not generating insights for multi page pdf's, so returning only text.\"\n",
    "                  \" Please watch this space for updates.\")\n",
    "            contents = []\n",
    "            text = ' '\n",
    "            pdfFileObj = open(self.file, 'rb')\n",
    "            pdfReader = PyPDF2.PdfFileReader(pdfFileObj)\n",
    "            pdfPages = pdfReader.getNumPages()\n",
    "            for val in range(pdfPages):\n",
    "                pageObject = pdfReader.getPage(val)\n",
    "                text = text + pageObject.extractText()\n",
    "            contents.append(text)\n",
    "            emp_df = pd.DataFrame()\n",
    "            if self.insights:\n",
    "                for val in range(pdfPages):\n",
    "                    conv = conversion(pdfReader.getPage(val))\n",
    "                    print(conv)\n",
    "#                     __conv = conv.convert()\n",
    "#                     print(__conv)\n",
    "                    insights = generate_insights(conv, emp_df)\n",
    "                    __insights = insights.generate_df()\n",
    "                    remove_files(__conv)\n",
    "                df1 = pd.concat([df, emp_df])\n",
    "                return df1\n",
    "            else:\n",
    "                return emp_df, contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "engaging-tobacco",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pdf('/home/anirudhpnbb/Downloads/Patterson Invoice 1.pdf', insights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "sharing-street",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are currently not generating insights for multi page pdf's, so returning only text. Please watch this space for updates.\n",
      "<__main__.conversion object at 0x7f7967ab6a20>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Can't convert object of type 'conversion' to 'str' for 'filename'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-76ed795d2c16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_pypdf2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-30-5307ae40e7a8>\u001b[0m in \u001b[0;36mextract_pypdf2\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m#                     print(__conv)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                     \u001b[0minsights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_insights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memp_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                     \u001b[0m__insights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minsights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m                     \u001b[0mremove_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__conv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memp_df\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-8e0083ce8d4b>\u001b[0m in \u001b[0;36mgenerate_df\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mtop_plus_height\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mleft_plus_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Can't convert object of type 'conversion' to 'str' for 'filename'"
     ]
    }
   ],
   "source": [
    "a.extract_pypdf2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "alpha-blind",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import pandas as pd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
